{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Month  Day Weekend?    Hour Collision Type         Injury Type  \\\n",
      "0  2015      1    5  Weekday     0.0          2-Car   No injury/unknown   \n",
      "1  2015      1    6  Weekday  1500.0          2-Car   No injury/unknown   \n",
      "2  2015      1    6  Weekend  2300.0          2-Car  Non-incapacitating   \n",
      "3  2015      1    7  Weekend   900.0          2-Car  Non-incapacitating   \n",
      "4  2015      1    7  Weekend  1100.0          2-Car   No injury/unknown   \n",
      "\n",
      "                          Primary Factor      Reported_Location   Latitude  \\\n",
      "0  OTHER (DRIVER) - EXPLAIN IN NARRATIVE             1ST & FESS  39.159207   \n",
      "1                  FOLLOWING TOO CLOSELY          2ND & COLLEGE  39.161440   \n",
      "2              DISREGARD SIGNAL/REG SIGN  BASSWOOD & BLOOMFIELD  39.149780   \n",
      "3          FAILURE TO YIELD RIGHT OF WAY         GATES & JACOBS  39.165655   \n",
      "4          FAILURE TO YIELD RIGHT OF WAY                  W 3RD  39.164848   \n",
      "\n",
      "   Longitude  \n",
      "0 -86.525874  \n",
      "1 -86.534848  \n",
      "2 -86.568890  \n",
      "3 -86.575956  \n",
      "4 -86.579625  \n"
     ]
    }
   ],
   "source": [
    "data_filepath = \"..\\\\dataset\\\\new dataset.xlsx\"\n",
    "df = pd.read_excel(data_filepath)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "**Feature Selection**\n",
    "Provided columns are 'Year', 'Month', 'Day', 'Weekend?', 'Hour', 'Collision Type', 'Injury Type','Primary Factor', 'Reported_Location', 'Latitude', 'Longitude'.\n",
    "\n",
    "Considering we only care about when/where accidents happen, we can remove all features that don't give use insight into these two factors. That means we can remove the 'Collision Type', 'Injury Type', and 'Primary Factor' features. We can also remove 'Year' since we want this model to generalize for any years. In further versions of this model once could use the year, month, and date to determine the weather at the time of crash and factor this feature into the model.\n",
    "\n",
    "**Removing Rows with Empty Values**\n",
    "We will also drop any rows with empty values in the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Month  Day Weekend?    Hour      Reported_Location   Latitude  Longitude\n",
      "0      1    5  Weekday     0.0             1ST & FESS  39.159207 -86.525874\n",
      "1      1    6  Weekday  1500.0          2ND & COLLEGE  39.161440 -86.534848\n",
      "2      1    6  Weekend  2300.0  BASSWOOD & BLOOMFIELD  39.149780 -86.568890\n",
      "3      1    7  Weekend   900.0         GATES & JACOBS  39.165655 -86.575956\n",
      "4      1    7  Weekend  1100.0                  W 3RD  39.164848 -86.579625\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['Collision Type', 'Injury Type', 'Primary Factor', 'Year'])\n",
    "df = df.dropna()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data\n",
    "**Normalizing Hours**\n",
    "\n",
    "Disregarding decimal points, Hour values are currently 3-4 characters with the least significant 2 digits being minutes (always 00 in this dataset) and the remaining significant bits denoting hours. We will remove decimal point and remove minutes integers so that the only remaining number is what number hour it is (from 0 to 23)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must normalize all values in hour column such that it is 4 integers indicating the format (HH:MM)\n",
    "df['Hour'] = df['Hour'].astype(int).astype(str).str.zfill(4)\n",
    "\n",
    "# get just the HH values (indicates which of the 24 buckets the value goes into)\n",
    "df['Hour'] = df['Hour'].str[:2].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding Weekend**\n",
    "\n",
    "Encode \"yes weekend\" to 1 and \"no weekend\" to 0 so we can use this feature in our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Month  Day  Weekend?  Hour      Reported_Location   Latitude  Longitude\n",
      "0      1    5         0     0             1ST & FESS  39.159207 -86.525874\n",
      "1      1    6         0    15          2ND & COLLEGE  39.161440 -86.534848\n",
      "2      1    6         1    23  BASSWOOD & BLOOMFIELD  39.149780 -86.568890\n",
      "3      1    7         1     9         GATES & JACOBS  39.165655 -86.575956\n",
      "4      1    7         1    11                  W 3RD  39.164848 -86.579625\n"
     ]
    }
   ],
   "source": [
    "weekend_mapping = {'Weekday':0, 'Weekend':1}\n",
    "df['Weekend?'] = df['Weekend?'].replace(weekend_mapping)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Month  Day  Weekend?  Hour      Reported_Location   Latitude  \\\n",
      "0          1    5         0     0             1ST & FESS  39.159207   \n",
      "1          1    6         0    15          2ND & COLLEGE  39.161440   \n",
      "2          1    6         1    23  BASSWOOD & BLOOMFIELD  39.149780   \n",
      "3          1    7         1     9         GATES & JACOBS  39.165655   \n",
      "4          1    7         1    11                  W 3RD  39.164848   \n",
      "...      ...  ...       ...   ...                    ...        ...   \n",
      "53938     10    6         0    17  DUNN & WHITE LOT WEST   0.000000   \n",
      "53939     11    3         0     8        RED OAK & SR446   0.000000   \n",
      "53940     12    5         0    12        2ND ST & WALNUT   0.000000   \n",
      "53941     12    1         1     7         NINETH & NORTH   0.000000   \n",
      "53942     12    7         1    17      MONROW & THIRD ST   0.000000   \n",
      "\n",
      "       Longitude  total_prob  \n",
      "0     -86.525874    8.503427  \n",
      "1     -86.534848    6.979846  \n",
      "2     -86.568890    9.381804  \n",
      "3     -86.575956    8.986231  \n",
      "4     -86.579625    8.715531  \n",
      "...          ...         ...  \n",
      "53938   0.000000    6.720038  \n",
      "53939   0.000000    7.746743  \n",
      "53940   0.000000    7.281432  \n",
      "53941   0.000000    9.460785  \n",
      "53942   0.000000    8.306544  \n",
      "\n",
      "[53660 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Probabilities\n",
    "total_crashes = df.shape[0]\n",
    "total_prob = []\n",
    "\n",
    "hour_prob = {}\n",
    "day_prob = {}\n",
    "month_prob = {}\n",
    "weekend_prob = {}\n",
    "\n",
    "# probability for each hour\n",
    "for hour in range(24):\n",
    "    occurrences_in_hour = df['Hour'].value_counts()[hour]\n",
    "    hour_prob[hour] = occurrences_in_hour/total_crashes\n",
    "\n",
    "for day in range(1,8):\n",
    "    occurrences_in_day = df['Day'].value_counts()[day]\n",
    "    day_prob[day] = occurrences_in_day/total_crashes\n",
    "\n",
    "months = df['Month'].unique()\n",
    "for month in months:\n",
    "    occurrences_in_month = df['Month'].value_counts()[month]\n",
    "    month_prob[month] = occurrences_in_month/total_crashes\n",
    "\n",
    "for weekend in range(2):\n",
    "    occurrences_in_weekend = df['Weekend?'].value_counts()[weekend]\n",
    "    weekend_prob[weekend] = occurrences_in_weekend/total_crashes\n",
    "    \n",
    "# Calculate total probability for each crash\n",
    "    \n",
    "# when calculating the total probability, the value gets extremely small due to multiplying\n",
    "    # probabilities. To reduce the effect of this we'll use log probabilities which shouldn't\n",
    "    # affect effectiveness of our product since we're simply comparing probabilities\n",
    "def CalculateTotalProb(row):\n",
    "    probabilities = [hour_prob[row['Hour']],\n",
    "                     day_prob[row['Day']],\n",
    "                     month_prob[row['Month']],\n",
    "                     weekend_prob[row['Weekend?']]]\n",
    "    log_probabilities = np.log(probabilities)\n",
    "    log_combined_probability  = np.sum(log_probabilities)\n",
    "    return log_combined_probability * -1\n",
    "\n",
    "df['total_prob'] = df.apply(CalculateTotalProb, axis=1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Modified Data\n",
    "\n",
    "Will save modified data to a CSV file for use by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('.\\\\modified_data\\\\cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1062708a37074d70712b695aadee582e0b0b9f95f45576b5521424137d05fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
