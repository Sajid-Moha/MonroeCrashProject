{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# so values can be viewed as scrollable element\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Month  Day  Weekend?  Hour  Injury Type   Latitude  Longitude\n",
      "0      1    5         0     0            0  39.159207 -86.525874\n",
      "1      1    6         0    15            0  39.161440 -86.534848\n",
      "2      1    6         1    23            1  39.149780 -86.568890\n",
      "3      1    7         1     9            1  39.165655 -86.575956\n",
      "4      1    7         1    11            0  39.164848 -86.579625\n"
     ]
    }
   ],
   "source": [
    "data_filepath = \".\\\\modified_data\\\\cleaned_data.csv\"\n",
    "df = pd.read_csv(data_filepath)\n",
    "\n",
    "# using drop Reported_Location since we can't use it\n",
    "df = df.drop(columns=['Reported_Location'])\n",
    "df[\"Injury Type\"] = df[\"Injury Type\"].map({0: 0, 1: 1, 2: 1, 3: 1})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model\n",
    "\n",
    "We determined through EDA that a simple model will not be sufficient to predict injury type. We will instead use more complicated models (Decision trees, naive bayes, SVM). If these models don't work, we will increase complexity even more to random forest and neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6535594483786806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      8265\n",
      "           1       0.26      0.28      0.27      2467\n",
      "\n",
      "    accuracy                           0.65     10732\n",
      "   macro avg       0.52      0.52      0.52     10732\n",
      "weighted avg       0.66      0.65      0.66     10732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# decision tree\n",
    "X = df.drop(columns=['Injury Type'])\n",
    "Y = df['Injury Type']\n",
    "\n",
    "# splitting data: Since we have a lot of data, we can use a 70-30 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=5)\n",
    "\n",
    "# create decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# train classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a big disparity between 0 values and 1 values which is leading to innacuracies for predicting 1 values. I will attempt to remedy by oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injury Type\n",
      "0    33091\n",
      "1     9837\n",
      "Name: count, dtype: int64\n",
      "Injury Type\n",
      "1    33091\n",
      "0    33091\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.6448005963473723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      8265\n",
      "           1       0.25      0.27      0.26      2467\n",
      "\n",
      "    accuracy                           0.64     10732\n",
      "   macro avg       0.51      0.51      0.51     10732\n",
      "weighted avg       0.66      0.64      0.65     10732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "print(y_train.value_counts())\n",
    "ros = RandomOverSampler()\n",
    "x_os, y_os = ros.fit_resample(X_train, y_train)\n",
    "print(y_os.value_counts())\n",
    "\n",
    "# train classifier\n",
    "clf.fit(x_os, y_os)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling barely affected the model performance; this indicates: our data is not good (either needs further cleaning + feature selection or injury type is random and can't be predicted), decision trees are not good for modeling this data, or we need to try different normalization. For now we will try other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue: Getting 0 predictions for 1-label so I must oversample as did previously to attempt to balance the number of 0 and 1 values in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injury Type\n",
      "0    33091\n",
      "1     9837\n",
      "Name: count, dtype: int64\n",
      "Injury Type\n",
      "1    33091\n",
      "0    33091\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.61      8265\n",
      "           1       0.26      0.59      0.36      2467\n",
      "\n",
      "    accuracy                           0.52     10732\n",
      "   macro avg       0.53      0.54      0.49     10732\n",
      "weighted avg       0.68      0.52      0.55     10732\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.49      0.51     33091\n",
      "           1       0.53      0.58      0.56     33091\n",
      "\n",
      "    accuracy                           0.54     66182\n",
      "   macro avg       0.54      0.54      0.54     66182\n",
      "weighted avg       0.54      0.54      0.54     66182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "# only use categorical attributes\n",
    "X_nb = df.drop(columns=['Injury Type', 'Latitude', 'Longitude'])\n",
    "Y_nb = df['Injury Type']\n",
    "\n",
    "# splitting data:\n",
    "X_nb_train, X_nb_test, y_nb_train, y_nb_test = train_test_split(X_nb, Y_nb, test_size=0.2, random_state=5)\n",
    "\n",
    "print(y_nb_train.value_counts())\n",
    "ros = RandomOverSampler()\n",
    "x_nb_os, y_nb_os = ros.fit_resample(X_nb_train, y_nb_train)\n",
    "print(y_nb_os.value_counts())\n",
    "\n",
    "clf_cat = CategoricalNB()\n",
    "clf_cat.fit(x_nb_os, np.asarray(y_nb_os))\n",
    "print(classification_report(y_nb_test, clf_cat.predict(X_nb_test)))\n",
    "\n",
    "# trying on training dataset\n",
    "print(classification_report(y_nb_os, clf_cat.predict(x_nb_os)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Still have poor performance**\n",
    "\n",
    "Let's try an SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecs171",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
